{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philipplukas/InvestigatingEmergence/blob/main/PretrainingTransformerXL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbJXYzABCQEO",
        "outputId": "5341dfdf-cd9e-4641-e486-f413922cac7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfwzQSB7CeSp",
        "outputId": "1d909847-c88d-48f3-bc20-8835f551aa89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -dr InvestigatingEmergence"
      ],
      "metadata": {
        "id": "sGcpXX8kWa7V"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UtIJ3IRB-Es",
        "outputId": "09934f69-5977-427d-c4cc-0c44c8fc26f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InvestigatingEmergence'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 11 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), 3.48 KiB | 25.00 KiB/s, done.\n",
            "Submodule 'transformer-xl' (https://github.com/kimiyoung/transformer-xl.git) registered for path 'transformer-xl'\n",
            "Cloning into '/content/drive/My Drive/InvestigatingEmergence/transformer-xl'...\n",
            "remote: Enumerating objects: 164, done.        \n",
            "remote: Total 164 (delta 0), reused 0 (delta 0), pack-reused 164        \n",
            "Receiving objects: 100% (164/164), 113.49 KiB | 5.16 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Submodule path 'transformer-xl': checked out '44781ed21dbaec88b280f74d9ae2877f52b492a5'\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/philipplukas/InvestigatingEmergence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af4qsGN2UxvH",
        "outputId": "b9c2892e-4622-4052-848e-e228b31d246c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/kimiyoung/transformer-xl\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/My Drive/InvestigatingEmergence\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyqLL2pASGid",
        "outputId": "67ba189e-cc42-475e-f544-91faeb761e1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/InvestigatingEmergence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"transformer-xl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLTFmgFBS8ov",
        "outputId": "afe37b18-0f64-4ee9-e7d4-87038c762c6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/InvestigatingEmergence/transformer-xl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACJb4pa8TGYI",
        "outputId": "3d5d18df-fff3-41cc-d5ce-32725c73a2c6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getdata.sh  LICENSE  prep_text8.py  pytorch  README.md\ttf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FfoAcyQ0DEol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7fd82c-ce66-44bc-d456-16d518dccd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Acquiring datasets ===\n",
            "---\n",
            "- Downloading WikiText-2 (WT2)\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!chmod u+x getdata.sh && ./getdata.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT_FmDM5KReU",
        "outputId": "b92decb3-732c-4191-d798-a9826ee2b727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/InvestigatingEmergence/transformer-xl/pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "OIrYqAPAKTiy"
      },
      "outputs": [],
      "source": [
        "!chmod u+x run_enwik8_base.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4deZQ0JVKgeS"
      },
      "outputs": [],
      "source": [
        "!./run_enwik8_base.sh train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wha6_FQefR"
      },
      "outputs": [],
      "source": [
        "\"\"\" ORIGNAL parameters\n",
        "\n",
        "python train.py \\\n",
        "        --cuda \\\n",
        "        --data ../data/enwik8/ \\\n",
        "        --dataset enwik8 \\\n",
        "        --n_layer 12 \\\n",
        "        --d_model 512 \\\n",
        "        --n_head 8 \\\n",
        "        --d_head 64 \\\n",
        "        --d_inner 2048 \\\n",
        "        --dropout 0.1 \\\n",
        "        --dropatt 0.0 \\\n",
        "        --optim adam \\\n",
        "        --lr 0.00025 \\\n",
        "        --warmup_step 0 \\\n",
        "        --max_step 400000 \\\n",
        "        --tgt_len 512 \\\n",
        "        --mem_len 512 \\\n",
        "        --eval_tgt_len 128 \\\n",
        "        --batch_size 22 \\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6APbnceLIqc",
        "outputId": "9f5f3d5b-0f15-4803-fffb-bbecfbc6bf7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment dir : LM-TFM-enwik8/20230301-130050\n",
            "Loading cached dataset...\n",
            "====================================================================================================\n",
            "    - data : ../data/enwik8/\n",
            "    - dataset : enwik8\n",
            "    - n_layer : 4\n",
            "    - n_head : 2\n",
            "    - d_head : 16\n",
            "    - d_embed : 128\n",
            "    - d_model : 128\n",
            "    - d_inner : 256\n",
            "    - dropout : 0.1\n",
            "    - dropatt : 0.0\n",
            "    - init : normal\n",
            "    - emb_init : normal\n",
            "    - init_range : 0.1\n",
            "    - emb_init_range : 0.01\n",
            "    - init_std : 0.02\n",
            "    - proj_init_std : 0.01\n",
            "    - optim : adam\n",
            "    - lr : 0.00025\n",
            "    - mom : 0.0\n",
            "    - scheduler : cosine\n",
            "    - warmup_step : 0\n",
            "    - decay_rate : 0.5\n",
            "    - lr_min : 0.0\n",
            "    - clip : 0.25\n",
            "    - clip_nonemb : False\n",
            "    - max_step : 400000\n",
            "    - batch_size : 22\n",
            "    - batch_chunk : 1\n",
            "    - tgt_len : 512\n",
            "    - eval_tgt_len : 128\n",
            "    - ext_len : 0\n",
            "    - mem_len : 512\n",
            "    - not_tied : False\n",
            "    - seed : 1111\n",
            "    - cuda : True\n",
            "    - adaptive : False\n",
            "    - div_val : 1\n",
            "    - pre_lnorm : False\n",
            "    - varlen : False\n",
            "    - multi_gpu : False\n",
            "    - log_interval : 200\n",
            "    - eval_interval : 4000\n",
            "    - work_dir : LM-TFM-enwik8/20230301-130050\n",
            "    - restart : False\n",
            "    - restart_dir : \n",
            "    - debug : False\n",
            "    - same_length : False\n",
            "    - attn_type : 0\n",
            "    - clamp_len : -1\n",
            "    - eta_min : 0.0\n",
            "    - gpu0_bsz : -1\n",
            "    - max_eval_steps : -1\n",
            "    - sample_softmax : -1\n",
            "    - patience : 0\n",
            "    - finetune_v2 : False\n",
            "    - finetune_v3 : False\n",
            "    - fp16 : False\n",
            "    - static_loss_scale : 1\n",
            "    - dynamic_loss_scale : False\n",
            "    - tied : True\n",
            "    - n_token : 204\n",
            "    - n_all_param : 374028\n",
            "    - n_nonemb_param : 347648\n",
            "====================================================================================================\n",
            "#params = 374028\n",
            "#non emb params = 347648\n",
            "/content/drive/MyDrive/Emergence/transformer-xl/pytorch/mem_transformer.py:266: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  attn_score = attn_score.float().masked_fill(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:197: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "| epoch   1 step      200 |    200 batches | lr 0.00025 | ms/batch 303.00 | loss  3.32 | bpc   4.78713\n",
            "| epoch   1 step      400 |    400 batches | lr 0.00025 | ms/batch 300.87 | loss  2.65 | bpc   3.81869\n",
            "| epoch   1 step      600 |    600 batches | lr 0.00025 | ms/batch 300.73 | loss  2.50 | bpc   3.61156\n",
            "| epoch   1 step      800 |    800 batches | lr 0.00025 | ms/batch 300.70 | loss  2.40 | bpc   3.46818\n",
            "| epoch   1 step     1000 |   1000 batches | lr 0.00025 | ms/batch 300.52 | loss  2.33 | bpc   3.36403\n",
            "| epoch   1 step     1200 |   1200 batches | lr 0.00025 | ms/batch 300.63 | loss  2.28 | bpc   3.29154\n",
            "| epoch   1 step     1400 |   1400 batches | lr 0.00025 | ms/batch 300.92 | loss  2.26 | bpc   3.26007\n",
            "| epoch   1 step     1600 |   1600 batches | lr 0.00025 | ms/batch 300.71 | loss  2.26 | bpc   3.25596\n",
            "| epoch   1 step     1800 |   1800 batches | lr 0.00025 | ms/batch 300.61 | loss  2.18 | bpc   3.14211\n",
            "| epoch   1 step     2000 |   2000 batches | lr 0.00025 | ms/batch 300.71 | loss  2.15 | bpc   3.10610\n",
            "| epoch   1 step     2200 |   2200 batches | lr 0.00025 | ms/batch 300.65 | loss  2.13 | bpc   3.06923\n",
            "| epoch   1 step     2400 |   2400 batches | lr 0.00025 | ms/batch 300.63 | loss  2.12 | bpc   3.05655\n",
            "| epoch   1 step     2600 |   2600 batches | lr 0.00025 | ms/batch 300.63 | loss  2.07 | bpc   2.97983\n",
            "| epoch   1 step     2800 |   2800 batches | lr 0.00025 | ms/batch 300.69 | loss  2.06 | bpc   2.97800\n",
            "| epoch   1 step     3000 |   3000 batches | lr 0.00025 | ms/batch 300.75 | loss  2.04 | bpc   2.93728\n",
            "| epoch   1 step     3200 |   3200 batches | lr 0.00025 | ms/batch 300.73 | loss  2.03 | bpc   2.92613\n",
            "| epoch   1 step     3400 |   3400 batches | lr 0.00025 | ms/batch 300.81 | loss  2.01 | bpc   2.89705\n",
            "| epoch   1 step     3600 |   3600 batches | lr 0.00025 | ms/batch 300.67 | loss  2.00 | bpc   2.88597\n",
            "| epoch   1 step     3800 |   3800 batches | lr 0.00025 | ms/batch 300.85 | loss  1.98 | bpc   2.85686\n",
            "| epoch   1 step     4000 |   4000 batches | lr 0.00025 | ms/batch 300.94 | loss  1.98 | bpc   2.85706\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Eval   1 at step     4000 | time: 1249.11s | valid loss  1.90 | bpc   2.74622\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "        --cuda \\\n",
        "        --data ../data/ctl/ \\\n",
        "        --dataset ctl \\\n",
        "        --n_layer 4 \\\n",
        "        --d_model 128 \\\n",
        "        --n_head 2 \\\n",
        "        --d_head 16 \\\n",
        "        --d_inner 256 \\\n",
        "        --dropout 0.1 \\\n",
        "        --dropatt 0.0 \\\n",
        "        --optim adam \\\n",
        "        --lr 0.00025 \\\n",
        "        --warmup_step 0 \\\n",
        "        --max_step 400000 \\\n",
        "        --tgt_len 512 \\\n",
        "        --mem_len 512 \\\n",
        "        --eval_tgt_len 128 \\\n",
        "        --batch_size 22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-272IMvftyW"
      },
      "source": [
        "## Pretraining on CTL task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwRM4paXgFFR",
        "outputId": "c4ce2ec5-8485-46fc-d277-7f48532faa52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/InvestigatingEmergence\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/InvestigatingEmergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ssYTpGwjgMwb"
      },
      "outputs": [],
      "source": [
        "from generate_task import CTLTask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XuykdlibgqDS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ttHq3r4ngTJt"
      },
      "outputs": [],
      "source": [
        "task = CTLTask()\n",
        "task.max_depth = 1\n",
        "base_tasks = task.generate_tasks()\n",
        "iterator = task.infinite_samples(base_tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3zhrhM0Ggt1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63928c8-92b1-4f1e-fb88-7a0a2c779a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘%%’: File exists\n",
            "mkdir: cannot create directory ‘mkdir’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data %% mkdir data/ctl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-tzpY9IkhDD8"
      },
      "outputs": [],
      "source": [
        "with open(\"data/ctl/train.txt\", 'w') as fp:\n",
        "  for i in range(100000):\n",
        "    fp.write(next(iterator) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C8fC-VkehZIc"
      },
      "outputs": [],
      "source": [
        "with open(\"data/ctl/valid.txt\", 'w') as fp:\n",
        "  for i in range(2000):\n",
        "    fp.write(next(iterator) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dh88BkyMkMe_"
      },
      "outputs": [],
      "source": [
        "with open(\"data/ctl/test.txt\", 'w') as fp:\n",
        "  for i in range(2000):\n",
        "    fp.write(next(iterator) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIOPAhT6kW0R",
        "outputId": "2f747d6d-19d7-418f-ed03-a7eed122c7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'transformer-xl/pytorch'\n",
            "/content/drive/My Drive/InvestigatingEmergence/transformer-xl\n"
          ]
        }
      ],
      "source": [
        "%cd transformer-xl/pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4AkmX1zkRPw",
        "outputId": "986276e5-8f77-497f-d41a-eb82365997e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment dir : LM-TFM-ctl/20230307-110317\n",
            "Loading cached dataset...\n",
            "====================================================================================================\n",
            "    - data : ../../data/ctl/\n",
            "    - dataset : ctl\n",
            "    - n_layer : 4\n",
            "    - n_head : 4\n",
            "    - d_head : 32\n",
            "    - d_embed : 128\n",
            "    - d_model : 128\n",
            "    - d_inner : 512\n",
            "    - dropout : 0.1\n",
            "    - dropatt : 0.0\n",
            "    - init : normal\n",
            "    - emb_init : normal\n",
            "    - init_range : 0.1\n",
            "    - emb_init_range : 0.01\n",
            "    - init_std : 0.02\n",
            "    - proj_init_std : 0.01\n",
            "    - optim : adam\n",
            "    - lr : 2e-05\n",
            "    - mom : 0.0\n",
            "    - scheduler : constant\n",
            "    - warmup_step : 0\n",
            "    - decay_rate : 0.5\n",
            "    - lr_min : 0.0\n",
            "    - clip : 0.25\n",
            "    - clip_nonemb : False\n",
            "    - max_step : 400000\n",
            "    - batch_size : 22\n",
            "    - batch_chunk : 1\n",
            "    - tgt_len : 512\n",
            "    - eval_tgt_len : 50\n",
            "    - ext_len : 0\n",
            "    - mem_len : 0\n",
            "    - not_tied : True\n",
            "    - seed : 1111\n",
            "    - cuda : True\n",
            "    - adaptive : False\n",
            "    - div_val : 1\n",
            "    - pre_lnorm : False\n",
            "    - varlen : False\n",
            "    - multi_gpu : False\n",
            "    - log_interval : 200\n",
            "    - eval_interval : 1000\n",
            "    - work_dir : LM-TFM-ctl/20230307-110317\n",
            "    - restart : False\n",
            "    - restart_dir : \n",
            "    - debug : False\n",
            "    - same_length : False\n",
            "    - attn_type : 0\n",
            "    - clamp_len : -1\n",
            "    - eta_min : 0.0\n",
            "    - gpu0_bsz : -1\n",
            "    - max_eval_steps : -1\n",
            "    - sample_softmax : -1\n",
            "    - patience : 0\n",
            "    - finetune_v2 : False\n",
            "    - finetune_v3 : False\n",
            "    - fp16 : False\n",
            "    - static_loss_scale : 1\n",
            "    - dynamic_loss_scale : False\n",
            "    - tied : False\n",
            "    - n_token : 24\n",
            "    - n_all_param : 863000\n",
            "    - n_nonemb_param : 856576\n",
            "====================================================================================================\n",
            "#params = 863000\n",
            "#non emb params = 856576\n",
            "/content/drive/MyDrive/InvestigatingEmergence/transformer-xl/pytorch/mem_transformer.py:266: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  attn_score = attn_score.float().masked_fill(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:197: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "| epoch   2 step      200 |     71 batches | lr 2e-05 | ms/batch 378.40 | loss  2.37 | ppl    10.656\n",
            "| epoch   4 step      400 |     13 batches | lr 2e-05 | ms/batch 377.51 | loss  1.51 | ppl     4.513\n",
            "| epoch   5 step      600 |     84 batches | lr 2e-05 | ms/batch 378.30 | loss  1.23 | ppl     3.409\n",
            "| epoch   7 step      800 |     26 batches | lr 2e-05 | ms/batch 377.38 | loss  1.08 | ppl     2.942\n",
            "| epoch   8 step     1000 |     97 batches | lr 2e-05 | ms/batch 378.44 | loss  0.88 | ppl     2.407\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Eval   1 at step     1000 | time: 378.31s | valid loss  0.81 | valid ppl     2.252\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| epoch  10 step     1200 |     39 batches | lr 2e-05 | ms/batch 379.13 | loss  0.73 | ppl     2.085\n",
            "| epoch  11 step     1400 |    110 batches | lr 2e-05 | ms/batch 378.50 | loss  0.66 | ppl     1.928\n",
            "| epoch  13 step     1600 |     52 batches | lr 2e-05 | ms/batch 377.44 | loss  0.62 | ppl     1.866\n",
            "| epoch  14 step     1800 |    123 batches | lr 2e-05 | ms/batch 378.29 | loss  0.60 | ppl     1.829\n",
            "| epoch  16 step     2000 |     65 batches | lr 2e-05 | ms/batch 377.72 | loss  0.59 | ppl     1.805\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Eval   2 at step     2000 | time: 378.15s | valid loss  0.63 | valid ppl     1.877\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| epoch  18 step     2200 |      7 batches | lr 2e-05 | ms/batch 379.14 | loss  0.58 | ppl     1.792\n",
            "| epoch  19 step     2400 |     78 batches | lr 2e-05 | ms/batch 378.43 | loss  0.58 | ppl     1.779\n",
            "| epoch  21 step     2600 |     20 batches | lr 2e-05 | ms/batch 377.41 | loss  0.57 | ppl     1.773\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Exiting from training early\n",
            "====================================================================================================\n",
            "| End of training | test loss  0.63 | test ppl     1.881\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "        --cuda \\\n",
        "        --data ../../data/ctl/ \\\n",
        "        --dataset ctl \\\n",
        "        --n_layer 4 \\\n",
        "        --d_model 128 \\\n",
        "        --n_head 4 \\\n",
        "        --d_head 32 \\\n",
        "        --d_inner 512 \\\n",
        "        --dropout 0.1 \\\n",
        "        --dropatt 0.0 \\\n",
        "        --optim adam \\\n",
        "        --lr 2e-05 \\\n",
        "        --warmup_step 0 \\\n",
        "        --max_step 400000 \\\n",
        "        --tgt_len 512 \\\n",
        "        --scheduler constant \\\n",
        "        --mem_len 0 \\\n",
        "        --ext_len 0 \\\n",
        "        --batch_size 22 \\\n",
        "        --not_tied \\\n",
        "        --eval-interval 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of model"
      ],
      "metadata": {
        "id": "JfwyafxPqYxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2echQOxyrLpz",
        "outputId": "1d18a344-adea-44fc-87fd-1b641d0a48b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'pytorch'\n",
            "/content/drive/My Drive/InvestigatingEmergence/transformer-xl/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUutpRZ7rZvU",
        "outputId": "267f74ef-fa84-41e7-ab96-5bdbc8c87d60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  getdata.sh  LICENSE  prep_text8.py  pytorch  README.md  tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mem_transformer import MemTransformerLM\n",
        "from data_utils import get_lm_corpus\n"
      ],
      "metadata": {
        "id": "Wka_-rXmrbBO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lNJZTZWCrsAI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/content/drive/MyDrive/InvestigatingEmergence/transformer-xl/pytorch/LM-TFM-ctl/20230307-110317/model.pt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Inc_uuB6HrB",
        "outputId": "8f931760-8f8a-4832-b052-cf47a102dc1a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MemTransformerLM(\n",
              "  (word_emb): AdaptiveEmbedding(\n",
              "    (emb_layers): ModuleList(\n",
              "      (0): Embedding(24, 128)\n",
              "    )\n",
              "    (emb_projs): ParameterList()\n",
              "  )\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (layers): ModuleList(\n",
              "    (0): RelPartialLearnableDecoderLayer(\n",
              "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
              "        (qkv_net): Linear(in_features=128, out_features=384, bias=False)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (dropatt): Dropout(p=0.0, inplace=False)\n",
              "        (o_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (r_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (pos_ff): PositionwiseFF(\n",
              "        (CoreNet): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): RelPartialLearnableDecoderLayer(\n",
              "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
              "        (qkv_net): Linear(in_features=128, out_features=384, bias=False)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (dropatt): Dropout(p=0.0, inplace=False)\n",
              "        (o_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (r_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (pos_ff): PositionwiseFF(\n",
              "        (CoreNet): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): RelPartialLearnableDecoderLayer(\n",
              "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
              "        (qkv_net): Linear(in_features=128, out_features=384, bias=False)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (dropatt): Dropout(p=0.0, inplace=False)\n",
              "        (o_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (r_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (pos_ff): PositionwiseFF(\n",
              "        (CoreNet): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (3): RelPartialLearnableDecoderLayer(\n",
              "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
              "        (qkv_net): Linear(in_features=128, out_features=384, bias=False)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (dropatt): Dropout(p=0.0, inplace=False)\n",
              "        (o_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (r_net): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (pos_ff): PositionwiseFF(\n",
              "        (CoreNet): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (crit): ProjectedAdaptiveLogSoftmax(\n",
              "    (out_layers): ModuleList(\n",
              "      (0): Linear(in_features=128, out_features=24, bias=True)\n",
              "    )\n",
              "    (out_projs): ParameterList(  (0): Object of type: NoneType)\n",
              "  )\n",
              "  (pos_emb): PositionalEmbedding()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \"PCe:011.\""
      ],
      "metadata": {
        "id": "aZaCkbxgs4YB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del get_lm_corpus"
      ],
      "metadata": {
        "id": "wIU8x38v5mIo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = get_lm_corpus('/content/drive/MyDrive/InvestigatingEmergence/data/ctl', 'ctl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XPWqdbFuIwT",
        "outputId": "520dba78-70e0-4aee-b361-201927a6fc32"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cached dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = corpus.vocab"
      ],
      "metadata": {
        "id": "PFxjAj6duzpC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = vocab.tokenize(test_input)"
      ],
      "metadata": {
        "id": "voRcish-wASi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpqqZQey0daL",
        "outputId": "bcd15575-744f-41a8-859e-3c879201c5b6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['P', 'C', 'e', ':', '0', '1', '1', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = vocab.encode_sents(tokenized)"
      ],
      "metadata": {
        "id": "nHQVU4c6u0Yb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = encoded[0].to(device='cuda')"
      ],
      "metadata": {
        "id": "00a6TAAs6WZB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = model._forward(encoded[0].reshape(1,-1))[0]"
      ],
      "metadata": {
        "id": "rnBqLbthEXS_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zqTWoNMP69g",
        "outputId": "92541534-1f2e-499b-ea0c-161f9b315250"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8713,  0.6302, -1.6254,  0.7747,  1.0746,  0.8525, -2.1163,\n",
              "           0.8879, -0.2778,  0.7046,  0.8404,  0.2602, -1.1572, -1.1093,\n",
              "          -0.6335,  1.3267,  0.6690,  0.6009, -0.9030,  1.3282, -1.0425,\n",
              "           0.6712,  0.4485,  0.8645,  0.4713, -0.3256, -0.5740,  1.1265,\n",
              "          -0.4830, -0.2819, -1.5795, -0.6691, -1.3927, -0.7132,  0.8412,\n",
              "          -0.9770,  1.5757, -0.5886, -0.9270,  0.8101,  1.3465,  1.2275,\n",
              "          -0.9836, -1.0858, -1.3419,  0.1219, -1.1723, -0.9212, -0.6683,\n",
              "           0.8550, -0.7383, -0.7051,  1.1626,  0.1884, -1.0734,  0.5911,\n",
              "           0.8621, -1.0743,  1.1788,  0.8624,  0.7972, -0.5683, -0.8697,\n",
              "          -0.9260,  1.1128,  2.3606,  0.7314,  1.0388, -1.1307,  1.3042,\n",
              "          -1.4518,  1.3202,  0.7782, -1.5742,  0.9142,  1.0308, -0.9864,\n",
              "          -1.3306, -0.9901, -1.1946,  0.9400, -0.8331,  1.6735, -0.5811,\n",
              "           1.0313,  0.8003, -0.9446,  0.5132, -0.8145, -1.0032, -0.5406,\n",
              "          -1.1596, -0.8925, -1.1434, -1.1523,  0.9688,  1.0482,  0.5369,\n",
              "           0.0690,  0.9666, -1.2412,  0.9903,  0.5212,  1.6347,  0.8321,\n",
              "          -0.8300, -1.0570,  0.7346,  1.2963, -1.3316,  0.9101,  1.5331,\n",
              "          -0.9800, -1.2139,  1.9446, -1.8665,  1.2612,  0.9564, -0.9662,\n",
              "          -0.8759,  0.9978, -1.8138, -0.3440,  0.6602,  1.4314, -1.3680,\n",
              "          -0.8245,  0.6294]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit = model.crit._compute_logit(hidden, model.crit.out_layers[0].weight,\n",
        "                                        model.crit.out_layers[0].bias, model.crit.out_projs[0])"
      ],
      "metadata": {
        "id": "6UW2hTz5PsRj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7YZXTn8P9Tv",
        "outputId": "99772073-7be3-476e-834a-65164ca291d7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1087, -0.1563,  0.1239,  0.0492,  0.3566, -0.1502, -0.2168,\n",
              "          -0.0235, -0.7082,  6.2037, -1.0107, -0.4975,  0.2330, -0.8392,\n",
              "          -0.6418,  0.1465,  0.1044, -0.0270,  0.1135, -0.4286,  0.0449,\n",
              "          -0.2254, -0.1221, -0.2554]]], device='cuda:0',\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.sym2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIPAe9rHwIix",
        "outputId": "baeb2112-88ff-4333-f215-12c64be0594b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('a', 0),\n",
              "             ('b', 1),\n",
              "             ('c', 2),\n",
              "             ('d', 3),\n",
              "             ('e', 4),\n",
              "             ('f', 5),\n",
              "             ('g', 6),\n",
              "             ('h', 7),\n",
              "             ('N', 8),\n",
              "             ('C', 9),\n",
              "             ('P', 10),\n",
              "             ('.', 11),\n",
              "             (':', 12),\n",
              "             ('0', 13),\n",
              "             ('1', 14),\n",
              "             ('2', 15),\n",
              "             ('3', 16),\n",
              "             ('4', 17),\n",
              "             ('5', 18),\n",
              "             ('6', 19),\n",
              "             ('7', 20),\n",
              "             ('8', 21),\n",
              "             ('9', 22),\n",
              "             ('<UNK>', 23)])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Arb4rO10wI22"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsPXFjZadUVAipjEQrcksh",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}